{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BaXivMXoVojm"
   },
   "source": [
    "# Language Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "90tX5XiUVqlk"
   },
   "source": [
    "Whenever we want to work with textual data, there is the need to identify the language it is written in. There is no difference if we are spellchecking a text, building a search index or search for the names of people, each of these tasks is always language dependent. Sometimes you can find metadata for the texts, where the language is mentioned. But this is not always the case and sometimes wrong. In those cases it is often easier to just detect the language.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WsTJvKLLWUzl"
   },
   "source": [
    "## 1 Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z-mwbEq4WefY"
   },
   "source": [
    "What exactly is the task?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ImxHTsRAWhw8"
   },
   "source": [
    "### 1.1 Number of Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KF_Z_V20WfNl"
   },
   "source": [
    "The task is easier if we only have to predict between two languages, instead of 3000. In a lot of practical cases we do have to choose from a couple of languages. For example if we collect Social Media Texts about a \"german topic\" or from a German Site, we can be very certain that the language is either German or English. This also applies to abstracts collected from the catalogue of a german library. \n",
    "\n",
    "In the following section we want to select from a small number of Western European languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJPR64o-WpF8"
   },
   "source": [
    "### 1.2 Text encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dEACqMuZWrVd"
   },
   "source": [
    "Worst case scenario: We dont even know the encoding a file is in. We are reading bits and bytes, we don't know whether we should convert it to ASCII, UTF8 or Latin2. In this cases we have to predict also the encoding, but we neglect this problem for this exercise and assume that all texts we read are coded in UTF8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s-7FUicvWt1P"
   },
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ULCgUV3uW0nE"
   },
   "source": [
    "A simple algorthm would be: How many typical/frequent German words do we find in a given text. First of all the text needs to have a sufficiant length to make precise predictions, as some words belong to different languages.\n",
    "Another frequently suggested approach is to count the occurance of stopwords, as stopwords are frequent (stopword lists are also easily accessible). This approach doesn't work with short texts. Words like 'de' and 'en' are for example part of the French and Dutch language/stopword list. Such double occurences are frequent, as stopwords are usually just one or two syllables long and the nummer of possible syllables is not infinite.\n",
    "\n",
    "A book title such as:\n",
    "\n",
    "*De kleine prins en de grote drakejacht*\n",
    "\n",
    "could be French or Dutch, if you only look at the stopwords. But someone who is familiar with both languages knows that it is a Dutch phrase.\n",
    "\n",
    "The best results are achieved when we are using character distributions as a feature and not word occurences.\n",
    "In English, the letter y is much more frequent then in German. On the other hand, German has characters (Umlaute) that do not appear in English at all. Even better are combinations of 2 or 3 letters, so called bi- and tri-gramms. We can also combine characters, bi- and trigramms as described in this paper:\n",
    "\n",
    "Cavnar, W.B., Trenkle, J.M.: *N-gram-based text categorization*. In: Proceedings of SDAIR-94, 3rd Annual Symposium on Document Analysis and Information Retrieval. pp. 161-175 (1994) http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.21.3248&rep=rep1&type=pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Nb32zZcW2Sk"
   },
   "source": [
    "### 2.1 Extraction of n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nxqXw_XmW5z9"
   },
   "source": [
    "The following function extracts ngrams from a string:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:35:48.903804Z",
     "start_time": "2018-04-11T00:35:48.897804Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WGg9ZStPUAv2"
   },
   "outputs": [],
   "source": [
    "def ngram(string, n):\n",
    "    liste = []\n",
    "    if n < len(string):\n",
    "        for p in range(len(string) - n + 1) :\n",
    "            tg = string[p:p+n]\n",
    "            liste.append(tg)\n",
    "    return liste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_QXkrXEoW-RW"
   },
   "source": [
    "Testing the fuction:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:35:48.911804Z",
     "start_time": "2018-04-11T00:35:48.907804Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1523360008481,
     "user": {
      "displayName": "Jean Charbonnier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108100613868726361526"
     },
     "user_tz": -120
    },
    "id": "0JTKbzHsU71F",
    "outputId": "dfbb52d6-a11b-468f-dfcd-df3138ffcf7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Die', 'ie ', 'e V', ' Ve', 'Ver', 'erf', 'rfa', 'fas', 'ass', 'sse', 'ser', 'eri', 'rin', 'in ', 'n u', ' un', 'unt', 'nte', 'ter', 'ern', 'rni', 'nim', 'imm', 'mmt', 'mt ', 't e', ' es', 'es ', 's i', ' in', 'in ', 'n d', ' di', 'die', 'ies', 'ese', 'sem', 'em ', 'm B', ' Bu', 'Buc', 'uch', 'che', 'he,', 'e, ', ', d', ' di', 'die', 'ie ', 'e G', ' Ge', 'Ges', 'esc', 'sch', 'chi', 'hic', 'ich', 'cht', 'hte', 'te ', 'e d', ' de', 'des', 'es ', 's K', ' Ka', 'Kau', 'aut', 'uts', 'tsc', 'sch', 'chu', 'huk', 'uks', 'ks ', 's i', ' in', 'in ', 'n M', ' Me', 'Men', 'ens', 'nsc', 'sch', 'che', 'hen', 'ens', 'nsc', 'sch', 'chi', 'hic', 'ick', 'cks', 'ksa', 'sal', 'ale', 'len', 'en ', 'n z', ' zu', 'zu ', 'u e', ' er', 'erz', 'rzä', 'zäh', 'ähl', 'hle', 'len', 'en.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Die Verfasserin unternimmt es in diesem Buche, die Geschichte des Kautschuks in Menschenschicksalen zu erzählen.\"\n",
    "trigramme = ngram(text,3)\n",
    "print(trigramme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OGt6ilPkXL9H"
   },
   "source": [
    "According to Cavnar et al. the best results are achieved by combining mono-, bi- and trigramms, so we write a functions that does exectly this (for  1≤n<4 ).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:35:48.918804Z",
     "start_time": "2018-04-11T00:35:48.915804Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zKc24jS8U-SE"
   },
   "outputs": [],
   "source": [
    "def xgram(string):\n",
    "    return [w for n in range(1,4) for w in ngram(string.lower(),n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:35:48.926804Z",
     "start_time": "2018-04-11T00:35:48.921804Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1523360019077,
     "user": {
      "displayName": "Jean Charbonnier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108100613868726361526"
     },
     "user_tz": -120
    },
    "id": "3zqnTIkMU_Uk",
    "outputId": "f5e30422-ec93-48fe-95c6-018ea19a8541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d', 'i', 'e', ' ', 'v', 'e', 'r', 'f', 'a', 's', 's', 'e', 'r', 'i', 'n', ' ', 'u', 'n', 't', 'e', 'r', 'n', 'i', 'm', 'm', 't', ' ', 'e', 's', ' ', 'i', 'n', ' ', 'd', 'i', 'e', 's', 'e', 'm', ' ', 'b', 'u', 'c', 'h', 'e', ',', ' ', 'd', 'i', 'e', ' ', 'g', 'e', 's', 'c', 'h', 'i', 'c', 'h', 't', 'e', ' ', 'd', 'e', 's', ' ', 'k', 'a', 'u', 't', 's', 'c', 'h', 'u', 'k', 's', ' ', 'i', 'n', ' ', 'm', 'e', 'n', 's', 'c', 'h', 'e', 'n', 's', 'c', 'h', 'i', 'c', 'k', 's', 'a', 'l', 'e', 'n', ' ', 'z', 'u', ' ', 'e', 'r', 'z', 'ä', 'h', 'l', 'e', 'n', '.', 'di', 'ie', 'e ', ' v', 've', 'er', 'rf', 'fa', 'as', 'ss', 'se', 'er', 'ri', 'in', 'n ', ' u', 'un', 'nt', 'te', 'er', 'rn', 'ni', 'im', 'mm', 'mt', 't ', ' e', 'es', 's ', ' i', 'in', 'n ', ' d', 'di', 'ie', 'es', 'se', 'em', 'm ', ' b', 'bu', 'uc', 'ch', 'he', 'e,', ', ', ' d', 'di', 'ie', 'e ', ' g', 'ge', 'es', 'sc', 'ch', 'hi', 'ic', 'ch', 'ht', 'te', 'e ', ' d', 'de', 'es', 's ', ' k', 'ka', 'au', 'ut', 'ts', 'sc', 'ch', 'hu', 'uk', 'ks', 's ', ' i', 'in', 'n ', ' m', 'me', 'en', 'ns', 'sc', 'ch', 'he', 'en', 'ns', 'sc', 'ch', 'hi', 'ic', 'ck', 'ks', 'sa', 'al', 'le', 'en', 'n ', ' z', 'zu', 'u ', ' e', 'er', 'rz', 'zä', 'äh', 'hl', 'le', 'en', 'n.', 'die', 'ie ', 'e v', ' ve', 'ver', 'erf', 'rfa', 'fas', 'ass', 'sse', 'ser', 'eri', 'rin', 'in ', 'n u', ' un', 'unt', 'nte', 'ter', 'ern', 'rni', 'nim', 'imm', 'mmt', 'mt ', 't e', ' es', 'es ', 's i', ' in', 'in ', 'n d', ' di', 'die', 'ies', 'ese', 'sem', 'em ', 'm b', ' bu', 'buc', 'uch', 'che', 'he,', 'e, ', ', d', ' di', 'die', 'ie ', 'e g', ' ge', 'ges', 'esc', 'sch', 'chi', 'hic', 'ich', 'cht', 'hte', 'te ', 'e d', ' de', 'des', 'es ', 's k', ' ka', 'kau', 'aut', 'uts', 'tsc', 'sch', 'chu', 'huk', 'uks', 'ks ', 's i', ' in', 'in ', 'n m', ' me', 'men', 'ens', 'nsc', 'sch', 'che', 'hen', 'ens', 'nsc', 'sch', 'chi', 'hic', 'ick', 'cks', 'ksa', 'sal', 'ale', 'len', 'en ', 'n z', ' zu', 'zu ', 'u e', ' er', 'erz', 'rzä', 'zäh', 'ähl', 'hle', 'len', 'en.']\n"
     ]
    }
   ],
   "source": [
    "xgramme = xgram(text)\n",
    "print(xgramme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4ZFdMVIXWNU"
   },
   "source": [
    "## 2.1 Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ddw85W3ZXYQU"
   },
   "source": [
    "A **model** for a language is a set of such n-gramms and their probabilities. In the following, a model is represented as a python dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:35:48.941804Z",
     "start_time": "2018-04-11T00:35:48.934804Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vSH5ryVOVAzc"
   },
   "outputs": [],
   "source": [
    "def buildmodel(text):\n",
    "    model = {}\n",
    "\n",
    "    xgramme = xgram(text)\n",
    "    nr_of_ngs = len(xgramme)\n",
    "\n",
    "    for w in xgramme:\n",
    "        f = 1 + model.get(w,0)\n",
    "        model[w] = f\n",
    "    \n",
    "    for w in model:\n",
    "        model[w] = float(model[w]) / float(nr_of_ngs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TPX0ELsZXbXN"
   },
   "source": [
    "Testing the function an printing the result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:35:48.949804Z",
     "start_time": "2018-04-11T00:35:48.943804Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1523360023153,
     "user": {
      "displayName": "Jean Charbonnier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108100613868726361526"
     },
     "user_tz": -120
    },
    "id": "rbKZNZmAVBwE",
    "outputId": "525d4f8c-51b9-42e7-9791-00842dccebac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' i': 0.006006006006006006, 'kau': 0.003003003003003003, 'as': 0.003003003003003003, 'hic': 0.006006006006006006, ' m': 0.003003003003003003, 'esc': 0.003003003003003003, 'zäh': 0.003003003003003003, 'sc': 0.012012012012012012, 'äh': 0.003003003003003003, 'cks': 0.003003003003003003, 'unt': 0.003003003003003003, 'se': 0.006006006006006006, 'ser': 0.003003003003003003, 'ch': 0.018018018018018018, 'huk': 0.003003003003003003, 'ic': 0.006006006006006006, 'che': 0.006006006006006006, 'rin': 0.003003003003003003, 'au': 0.003003003003003003, 't ': 0.003003003003003003, 'mt': 0.003003003003003003, 'e, ': 0.003003003003003003, 'ka': 0.003003003003003003, 'sa': 0.003003003003003003, 'ale': 0.003003003003003003, 'ut': 0.003003003003003003, ' er': 0.003003003003003003, 'm': 0.012012012012012012, 'u e': 0.003003003003003003, 'in': 0.009009009009009009, 'uk': 0.003003003003003003, 'zu ': 0.003003003003003003, 'ns': 0.006006006006006006, 'des': 0.003003003003003003, ' g': 0.003003003003003003, 'm ': 0.003003003003003003, 'n': 0.02702702702702703, 'ni': 0.003003003003003003, 'men': 0.003003003003003003, 'n m': 0.003003003003003003, 'ter': 0.003003003003003003, ' es': 0.003003003003003003, 'rni': 0.003003003003003003, 'ä': 0.003003003003003003, 'he,': 0.003003003003003003, 'ass': 0.003003003003003003, 'un': 0.003003003003003003, 'te': 0.006006006006006006, 'en ': 0.003003003003003003, 'nte': 0.003003003003003003, 'd': 0.012012012012012012, 'ens': 0.006006006006006006, 'e d': 0.003003003003003003, ' me': 0.003003003003003003, 'bu': 0.003003003003003003, 'imm': 0.003003003003003003, 'nt': 0.003003003003003003, 'g': 0.003003003003003003, ' in': 0.006006006006006006, 'rzä': 0.003003003003003003, 'mt ': 0.003003003003003003, 'ese': 0.003003003003003003, 'ie': 0.009009009009009009, 'u ': 0.003003003003003003, 'mmt': 0.003003003003003003, 'in ': 0.009009009009009009, 'n u': 0.003003003003003003, 'ks': 0.006006006006006006, 'cht': 0.003003003003003003, 'm b': 0.003003003003003003, 'ht': 0.003003003003003003, 'es ': 0.006006006006006006, 'en': 0.012012012012012012, 'f': 0.003003003003003003, 'te ': 0.003003003003003003, 'uch': 0.003003003003003003, 'e g': 0.003003003003003003, 'ri': 0.003003003003003003, 'i': 0.02702702702702703, 'e,': 0.003003003003003003, 'erf': 0.003003003003003003, 'er': 0.012012012012012012, 'ick': 0.003003003003003003, 't': 0.012012012012012012, 'me': 0.003003003003003003, 'rn': 0.003003003003003003, 'sse': 0.003003003003003003, 'a': 0.009009009009009009, 's k': 0.003003003003003003, 'rz': 0.003003003003003003, ' z': 0.003003003003003003, 'en.': 0.003003003003003003, 'de': 0.003003003003003003, ' b': 0.003003003003003003, 'tsc': 0.003003003003003003, 'uts': 0.003003003003003003, 'hen': 0.003003003003003003, 'u': 0.015015015015015015, 'n d': 0.003003003003003003, 'ks ': 0.003003003003003003, 'rf': 0.003003003003003003, 'mm': 0.003003003003003003, 'e ': 0.009009009009009009, 'di': 0.009009009009009009, 'v': 0.003003003003003003, 'e': 0.05105105105105105, 'l': 0.006006006006006006, ' k': 0.003003003003003003, 'chu': 0.003003003003003003, 'erz': 0.003003003003003003, 'r': 0.012012012012012012, 'ss': 0.003003003003003003, 'k': 0.009009009009009009, ' di': 0.006006006006006006, 's': 0.03303303303303303, 'hi': 0.006006006006006006, 'ern': 0.003003003003003003, 'hl': 0.003003003003003003, 'ähl': 0.003003003003003003, 'hu': 0.003003003003003003, 'ts': 0.003003003003003003, 'c': 0.021021021021021023, 'sch': 0.012012012012012012, 'die': 0.009009009009009009, ' v': 0.003003003003003003, 'im': 0.003003003003003003, 'e v': 0.003003003003003003, 'ck': 0.003003003003003003, ', ': 0.003003003003003003, 'fas': 0.003003003003003003, ', d': 0.003003003003003003, 'sal': 0.003003003003003003, ' d': 0.009009009009009009, '.': 0.003003003003003003, 'al': 0.003003003003003003, ' ': 0.042042042042042045, 'es': 0.012012012012012012, 'ges': 0.003003003003003003, 'hle': 0.003003003003003003, 'sem': 0.003003003003003003, ' e': 0.006006006006006006, ' bu': 0.003003003003003003, 'n z': 0.003003003003003003, 'n ': 0.012012012012012012, 'ich': 0.003003003003003003, 'em': 0.003003003003003003, 'he': 0.006006006006006006, 'buc': 0.003003003003003003, 't e': 0.003003003003003003, ' zu': 0.003003003003003003, 's i': 0.006006006006006006, 'h': 0.021021021021021023, 'b': 0.003003003003003003, 'le': 0.006006006006006006, 'uks': 0.003003003003003003, 'ver': 0.003003003003003003, 'ge': 0.003003003003003003, 'eri': 0.003003003003003003, 'chi': 0.006006006006006006, 'uc': 0.003003003003003003, 'nim': 0.003003003003003003, ' u': 0.003003003003003003, 'aut': 0.003003003003003003, 'zu': 0.003003003003003003, 've': 0.003003003003003003, 'ie ': 0.006006006006006006, 's ': 0.009009009009009009, ' ve': 0.003003003003003003, 'zä': 0.003003003003003003, 'ksa': 0.003003003003003003, 'nsc': 0.006006006006006006, 'z': 0.006006006006006006, 'em ': 0.003003003003003003, 'ies': 0.003003003003003003, ' ge': 0.003003003003003003, ',': 0.003003003003003003, ' de': 0.003003003003003003, 'n.': 0.003003003003003003, ' ka': 0.003003003003003003, 'fa': 0.003003003003003003, 'rfa': 0.003003003003003003, 'len': 0.006006006006006006, ' un': 0.003003003003003003, 'hte': 0.003003003003003003}\n"
     ]
    }
   ],
   "source": [
    "model = buildmodel(text)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jXuFFkx9Xd01"
   },
   "source": [
    "We could also use a Lib:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:35:48.958804Z",
     "start_time": "2018-04-11T00:35:48.951804Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8hTlqoA0VDOd"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def buildmodel(text):\n",
    "    model = collections.Counter(xgram(text))  \n",
    "    nr_of_ngs = sum(model.values())\n",
    "\n",
    "    for w in model:\n",
    "        model[w] = float(model[w]) / float(nr_of_ngs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:35:48.971804Z",
     "start_time": "2018-04-11T00:35:48.960804Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1523360030849,
     "user": {
      "displayName": "Jean Charbonnier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108100613868726361526"
     },
     "user_tz": -120
    },
    "id": "UycKWSi7VEJm",
    "outputId": "2b23ff5c-602c-4a17-acca-dde141c53933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'e': 0.05105105105105105, ' ': 0.042042042042042045, 's': 0.03303303303303303, 'n': 0.02702702702702703, 'i': 0.02702702702702703, 'c': 0.021021021021021023, 'h': 0.021021021021021023, 'ch': 0.018018018018018018, 'u': 0.015015015015015015, 'sc': 0.012012012012012012, 'm': 0.012012012012012012, 'd': 0.012012012012012012, 'en': 0.012012012012012012, 'er': 0.012012012012012012, 't': 0.012012012012012012, 'r': 0.012012012012012012, 'sch': 0.012012012012012012, 'es': 0.012012012012012012, 'n ': 0.012012012012012012, 'in': 0.009009009009009009, 'ie': 0.009009009009009009, 'in ': 0.009009009009009009, 'a': 0.009009009009009009, 'e ': 0.009009009009009009, 'di': 0.009009009009009009, 'k': 0.009009009009009009, 'die': 0.009009009009009009, ' d': 0.009009009009009009, 's ': 0.009009009009009009, ' i': 0.006006006006006006, 'hic': 0.006006006006006006, 'se': 0.006006006006006006, 'ic': 0.006006006006006006, 'che': 0.006006006006006006, 'ns': 0.006006006006006006, 'te': 0.006006006006006006, 'ens': 0.006006006006006006, ' in': 0.006006006006006006, 'ks': 0.006006006006006006, 'es ': 0.006006006006006006, 'l': 0.006006006006006006, ' di': 0.006006006006006006, 'hi': 0.006006006006006006, ' e': 0.006006006006006006, 'he': 0.006006006006006006, 's i': 0.006006006006006006, 'le': 0.006006006006006006, 'chi': 0.006006006006006006, 'ie ': 0.006006006006006006, 'nsc': 0.006006006006006006, 'z': 0.006006006006006006, 'len': 0.006006006006006006, 'kau': 0.003003003003003003, 'as': 0.003003003003003003, ' m': 0.003003003003003003, 'esc': 0.003003003003003003, 'zäh': 0.003003003003003003, 'äh': 0.003003003003003003, 'cks': 0.003003003003003003, 'unt': 0.003003003003003003, 'ser': 0.003003003003003003, 'huk': 0.003003003003003003, 'rin': 0.003003003003003003, 'au': 0.003003003003003003, 't ': 0.003003003003003003, 'mt': 0.003003003003003003, 'e, ': 0.003003003003003003, 'ka': 0.003003003003003003, 'sa': 0.003003003003003003, 'ale': 0.003003003003003003, 'ut': 0.003003003003003003, ' er': 0.003003003003003003, 'u e': 0.003003003003003003, 'uk': 0.003003003003003003, 'zu ': 0.003003003003003003, 'des': 0.003003003003003003, ' g': 0.003003003003003003, 'm ': 0.003003003003003003, 'ni': 0.003003003003003003, 'men': 0.003003003003003003, 'n m': 0.003003003003003003, 'ter': 0.003003003003003003, ' es': 0.003003003003003003, 'rni': 0.003003003003003003, 'ä': 0.003003003003003003, 'he,': 0.003003003003003003, 'ass': 0.003003003003003003, 'un': 0.003003003003003003, 'en ': 0.003003003003003003, 'nte': 0.003003003003003003, 'e d': 0.003003003003003003, ' me': 0.003003003003003003, 'bu': 0.003003003003003003, 'imm': 0.003003003003003003, 'nt': 0.003003003003003003, 'g': 0.003003003003003003, 'rzä': 0.003003003003003003, 'mt ': 0.003003003003003003, 'ese': 0.003003003003003003, 'u ': 0.003003003003003003, 'mmt': 0.003003003003003003, 'n u': 0.003003003003003003, 'cht': 0.003003003003003003, 'm b': 0.003003003003003003, 'ht': 0.003003003003003003, 'f': 0.003003003003003003, 'te ': 0.003003003003003003, 'uch': 0.003003003003003003, 'e g': 0.003003003003003003, 'ri': 0.003003003003003003, 'e,': 0.003003003003003003, 'erf': 0.003003003003003003, 'ick': 0.003003003003003003, 'me': 0.003003003003003003, 'rn': 0.003003003003003003, 'sse': 0.003003003003003003, 's k': 0.003003003003003003, 'rz': 0.003003003003003003, ' z': 0.003003003003003003, 'en.': 0.003003003003003003, 'de': 0.003003003003003003, ' b': 0.003003003003003003, 'tsc': 0.003003003003003003, 'uts': 0.003003003003003003, 'hen': 0.003003003003003003, 'n d': 0.003003003003003003, 'ks ': 0.003003003003003003, 'rf': 0.003003003003003003, 'mm': 0.003003003003003003, 'v': 0.003003003003003003, ' k': 0.003003003003003003, 'chu': 0.003003003003003003, 'erz': 0.003003003003003003, 'ss': 0.003003003003003003, 'ern': 0.003003003003003003, 'hl': 0.003003003003003003, 'ähl': 0.003003003003003003, 'hu': 0.003003003003003003, 'ts': 0.003003003003003003, ' v': 0.003003003003003003, 'im': 0.003003003003003003, 'e v': 0.003003003003003003, 'ck': 0.003003003003003003, ', ': 0.003003003003003003, 'fas': 0.003003003003003003, ', d': 0.003003003003003003, 'sal': 0.003003003003003003, '.': 0.003003003003003003, 'al': 0.003003003003003003, 'ges': 0.003003003003003003, 'hle': 0.003003003003003003, 'sem': 0.003003003003003003, ' bu': 0.003003003003003003, 'n z': 0.003003003003003003, 'ich': 0.003003003003003003, 'em': 0.003003003003003003, 'buc': 0.003003003003003003, 't e': 0.003003003003003003, ' zu': 0.003003003003003003, 'b': 0.003003003003003003, 'uks': 0.003003003003003003, 'ver': 0.003003003003003003, 'ge': 0.003003003003003003, 'eri': 0.003003003003003003, 'uc': 0.003003003003003003, 'nim': 0.003003003003003003, ' u': 0.003003003003003003, 'aut': 0.003003003003003003, 'zu': 0.003003003003003003, 've': 0.003003003003003003, ' ve': 0.003003003003003003, 'zä': 0.003003003003003003, 'ksa': 0.003003003003003003, 'em ': 0.003003003003003003, 'ies': 0.003003003003003003, ' ge': 0.003003003003003003, ',': 0.003003003003003003, ' de': 0.003003003003003003, 'n.': 0.003003003003003003, ' ka': 0.003003003003003003, 'fa': 0.003003003003003003, 'rfa': 0.003003003003003003, ' un': 0.003003003003003003, 'hte': 0.003003003003003003})\n"
     ]
    }
   ],
   "source": [
    "model = buildmodel(text)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wuyvPnM7XjiM"
   },
   "source": [
    "Given a sufficient amout of text, we can get values that are typical for a language. We can use these values  to compare it with the values of an unknown text.\n",
    "\n",
    "**NLTK** offers the Declaration of Human Rights in over 300 languages. We will use those texts to build some language models, though the amount fo texts in fact is too small to get relyable models.\n",
    "\n",
    "Eventually, you have to download the NLTK ressources. This has only to be done once. If you execute the code in the next cell a dialog window will open. Select download and then the option 'book' (or 'all' or just 'udhr').\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:35:48.977804Z",
     "start_time": "2018-04-11T00:35:48.974804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove comment signs if needed\n",
    "#\n",
    "#import nltk\n",
    "#\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:35:52.967804Z",
     "start_time": "2018-04-11T00:35:48.981804Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-m5iOlmuVGFc"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import udhr\n",
    "\n",
    "#print udhr.fileids()\n",
    "\n",
    "languages = ['english','german','dutch','french','italian','spanish']\n",
    "\n",
    "\"\"\"Warning the text should be from same domain. Else there will be issues\"\"\"\n",
    "english_udhr = udhr.raw('English-Latin1')\n",
    "german_udhr = udhr.raw('German_Deutsch-Latin1')\n",
    "dutch_udhr = udhr.raw('Dutch_Nederlands-Latin1')\n",
    "french_udhr = udhr.raw('French_Francais-Latin1')\n",
    "italian_udhr = udhr.raw('Italian_Italiano-Latin1')\n",
    "spanish_udhr = udhr.raw('Spanish_Espanol-Latin1')\n",
    "\n",
    "texts = {'english':english_udhr,'german':german_udhr,'dutch':dutch_udhr,'french':french_udhr,'italian':italian_udhr,'spanish':spanish_udhr}\n",
    "models = {lang:buildmodel(texts[lang]) for lang in languages}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HH4UGlmpXnd9"
   },
   "source": [
    "These texts are very short and contain only a fraction of the words that belong to the vocabulary of a language. The German version is only 10 000 Characters long:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:35:52.974804Z",
     "start_time": "2018-04-11T00:35:52.969804Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1523360034413,
     "user": {
      "displayName": "Jean Charbonnier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108100613868726361526"
     },
     "user_tz": -120
    },
    "id": "WcvKv0QZVItX",
    "outputId": "f19a1166-38ea-4f16-beb5-32ca374bd446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n"
     ]
    }
   ],
   "source": [
    "print(len(german_udhr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bo5e34svXooF"
   },
   "source": [
    "## 3. Determine the Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NjrYEMklXsss"
   },
   "source": [
    "We know have to compare the frequencies of the n-grams of a given text to the frequencies of a model. We will use Cosine Similarity for this:\n",
    "\n",
    "Wir müssen jetzt die n-Gram Frequenzen eiens Textes mit den Frequenzen der Modelle vergleichen. Um die Modelle zu vergleichen berechnen wir den Cosinus:\n",
    "\n",
    "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/a71c4add4abded66efd42b202c76f6a59944a587)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:35:52.981804Z",
     "start_time": "2018-04-11T00:35:52.976804Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9V9uWT7nVJvE"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def cosine(a,b):\n",
    "    return sum([a[k]*b[k] for k in a if k in b]) / (math.sqrt(sum([a[k]**2 for k in a])) * math.sqrt(sum([b[k]**2 for k in b])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:35:53.001804Z",
     "start_time": "2018-04-11T00:35:52.984804Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1523360037009,
     "user": {
      "displayName": "Jean Charbonnier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108100613868726361526"
     },
     "user_tz": -120
    },
    "id": "dBFUeFXoVKw8",
    "outputId": "ed1f4297-7f69-4366-d5e3-04aef9d3667f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Verfasserin unternimmt es in diesem Buche, die Geschichte des Kautschuks in Menschenschicksalen zu erzählen.\n",
      "spanish 0.7444444064683357\n",
      "german 0.852209256728064\n",
      "english 0.741116098902326\n",
      "italian 0.7148098723419043\n",
      "dutch 0.7916873428505521\n",
      "french 0.7659701598838548\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "textmodel = buildmodel(text)\n",
    "for m in models:\n",
    "    print(m, cosine(models[m],textmodel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TZkeYVrgXv62"
   },
   "source": [
    "We already get decent results. Of course the accuracy could be increased if we use longer texts from a different set of genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rZvR5U_GXxFt"
   },
   "source": [
    "## 4. Beautify it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WoEx_2lFX0k0"
   },
   "source": [
    "We need a function that predicts in which language a text is written in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:36:29.310804Z",
     "start_time": "2018-04-11T00:36:29.303804Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MDOZVaHNVMAk"
   },
   "outputs": [],
   "source": [
    "def guess_language(text):\n",
    "    textmodel = buildmodel(text)\n",
    "    lang = \"english\"\n",
    "    best = 0\n",
    "    for m in models:\n",
    "        c = cosine(models[m],textmodel)\n",
    "        if c > best:\n",
    "            best = c\n",
    "            lang = m\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:36:30.114804Z",
     "start_time": "2018-04-11T00:36:30.074804Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1523360041673,
     "user": {
      "displayName": "Jean Charbonnier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108100613868726361526"
     },
     "user_tz": -120
    },
    "id": "BAg-dgYlVM7d",
    "outputId": "a25509fd-8ff6-40a7-de27-6545721a1e51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dutch\n",
      "french\n",
      "spanish\n"
     ]
    }
   ],
   "source": [
    "t = \"Wie zijn leven voltooid vindt en met een consulent in gesprek gaat over zelfdoding, stelt zelfeuthanasie vaak uit of ziet ervan af\"  \n",
    "print(guess_language(t))\n",
    "\n",
    "t = u\"L’ancien candidat écologiste à la primaire de la gauche s’était engagé à soutenir le vainqueur de ce scrutin à la fin janvier, en l’occurrence Benoît Hamon.\"  \n",
    "print(guess_language(t))\n",
    "\n",
    "\n",
    "t = \"Una capra al posto del giardiniere\"\n",
    "print(guess_language(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "brK9km7LX22V"
   },
   "source": [
    "The last Result is wrong. Italian would be right. The text is very short and the modell is based on a too small corpus.\n",
    "\n",
    "Also, to not always calculate the models anew, we can pickle them and save them to google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:37:07.551804Z",
     "start_time": "2018-04-11T00:37:07.523804Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fqJgUz5cX3Ie"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#from pydrive.auth import GoogleAuth\n",
    "#from pydrive.drive import GoogleDrive\n",
    "#from google.colab import auth\n",
    "#from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Save model with pickle\n",
    "pickle.dump(models, open('langidmodels.pkl', 'wb'))\n",
    "\n",
    "\n",
    "# 1. Authenticate and create the PyDrive client.\n",
    "#auth.authenticate_user()\n",
    "#gauth = GoogleAuth()\n",
    "#gauth.credentials = GoogleCredentials.get_application_default()\n",
    "#drive = GoogleDrive(gauth)  \n",
    "\n",
    "# get the folder id where you want to save your file\n",
    "#file = drive.CreateFile({'parents':[{u'id': folder_id}]})\n",
    "#file.SetContentFile('langidmodels.pkl')\n",
    "#file.Upload() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:37:08.622804Z",
     "start_time": "2018-04-11T00:37:08.606804Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jW0wYcpCabql"
   },
   "outputs": [],
   "source": [
    "models = pickle.load(open('langidmodels.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OLjlz4YhYLVw"
   },
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UCWnOTt9YOCf"
   },
   "source": [
    "\n",
    "1.   Test the classifier with different longer and shorter texts\n",
    "2.   Add languages. Especially difficult languages that are very similar to those that are already added.\n",
    "3.   Search for bigger text corpora. Here is a list of those available in NLTK: http://www.nltk.org/book/ch02.html . For German you can use the Tiger-Corpus: http://www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/tiger.html (Also available on Moodle)\n",
    "\n",
    "This is how you can read the corpus:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:35:53.134804Z",
     "start_time": "2018-04-10T22:35:49.036Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hMFVry4xYMJv"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such file or directory: '/home/saurabh/NLP/Corpora'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-28789ddd1867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcolumntypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtiger_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConllCorpusReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfileid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumntypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/corpus/reader/conll.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, fileids, columntypes, chunk_types, root_label, pos_in_tree, srl_includes_roleset, encoding, tree_class, tagset)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_srl_includes_roleset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrl_includes_roleset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tree_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mCorpusReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tagset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/corpus/reader/api.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, fileids, encoding, tagset)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZipFilePathPointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzipentry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileSystemPathPointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPathPointer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CorpusReader: expected a string or a PathPointer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/compat.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_py3_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_decorator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, _path)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such file or directory: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: No such file or directory: '/home/saurabh/NLP/Corpora'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "root = 'Corpora'\n",
    "fileid = 'tiger.16012013.conll09'\n",
    "columntypes = ['ignore','words','ignore','ignore','pos']\n",
    "\n",
    "tiger_corpus = nltk.corpus.ConllCorpusReader(root,fileid,columntypes,encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37MmqW0qYaTQ"
   },
   "source": [
    "You can get a list of words, from which you can reconstruct the text or you can modify the n-gram algorithm to use a list of words as input instead of a text. In later cases, it is usefull to add a special character in the beginning and at the end of a word to destinguish between word beginning and end. Diktator would become %Diktator%, which would result in 2-grams '%D' and 'r%' - representing that a word in german would beginn with an D and end with an r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:35:53.134804Z",
     "start_time": "2018-04-10T22:35:49.044Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xBau9x92YbHK"
   },
   "outputs": [],
   "source": [
    "text_german = tiger_corpus.words()\n",
    "print(len(text_german))\n",
    "print(text_german[:10])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "PredictingLanguage.ipynb",
   "provenance": [
    {
     "file_id": "1CUUuJZjBPzX3mLpoTEFxz0jRJCqA_jgN",
     "timestamp": 1523361370810
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
